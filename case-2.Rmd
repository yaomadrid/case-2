---
title: "case-2"
output: html_document
---

#Part 1
```{r}
library(readr)
library(dplyr)
library(broom)
rockyDB <- read_csv("rockyDB.csv")

#a
colnames(rockyDB)[2] <- 'Rocky1'
colnames(rockyDB)[3] <- 'Rocky2'
colnames(rockyDB)[4] <- 'Rocky3'
colnames(rockyDB)[5] <- 'Rocky4'
colnames(rockyDB)[6] <- 'Rocky5'

```

#b
There are several reasons why missing value is available. Some people did not watch that particular Rocky movie because they were not satisfied with previous Rocky movie or they just never heard of the movie series before. Some people may watch the movie, but disliked and did not want to rate it. We cannot use "0" to represent different attitudes from different groups of people. Besides, if we replace all missing value with 0, we will underestimate ratings, since the lowest rating people can give is 1.Therefore, representing missing value with "0" can cause problems for future analysis.


#c
```{r }
rockyDB$Rocky1<-replace(rockyDB$Rocky1,rockyDB$Rocky1==0, NA)
rockyDB$Rocky2<-replace(rockyDB$Rocky2,rockyDB$Rocky2==0, NA)
rockyDB$Rocky3<-replace(rockyDB$Rocky3,rockyDB$Rocky3==0, NA)
rockyDB$Rocky4<-replace(rockyDB$Rocky4,rockyDB$Rocky4==0, NA)
rockyDB$Rocky5<-replace(rockyDB$Rocky5,rockyDB$Rocky5==0, NA)

```

=======

Part 2

#a
```{r}

install.packages("corrplot")
library("corrplot")
CorMovie<-cor(rockyDB[,2:6],use="pairwise.complete.obs")
round(CorMovie, digits = 3)
corrplot(CorMovie,order="hclust")
```
According to the correlation plot, Rocky2, Rocky 3 and Rocky 4 are within a cluster and the color of their dots are darkest.
Therefore, these movies are most similar. Also, the correlation coefficient of ratings between these three movies are above 0.6.
Rocky 1 is most different from the others, the coefficients of ratings between Rocky 1 and other movies are relative low, compared with others. And the correlation plot also indicates the same conclution.

#b

```{r}
colMeans(x=rockyDB[,2:6], na.rm = TRUE)
```
The mean of ratings of Rocky4 is highest, so it is best. However, the mean of ratings of Rocky5 is lowest, therefore it is worst.

#c
```{r}
RatedRocky4<-rockyDB[!is.na(rockyDB$Rocky4),]
View(RatedRocky4)
colMeans(x=RatedRocky4[,2:6], na.rm = TRUE)
```
The mean ratings of Rocky1, Rocky2 and Rocky 3 increased a lot, compared to the results of previous section. It is reasonable. People who rated Rocky 4  very likely had watched previous three movies and spoken highly of them. That's why they are willing to watch the next one, Rocky 4. This data frame excludes people who watched previous three movies but felt disappointed about the movie and then stopped to support this Rocky series. Therefore, it is possible that a lot of low ratings are not available in the new data frame and only high ratings are left. Therefore, the means of previous three movies rise.

#d
```{r}
rockyDB_noNA<- na.omit(rockyDB)
colMeans(x=rockyDB_noNA[,2:6], na.rm = TRUE)
```
It is common that data of some movies are missing. One explanation is that people do not watch the later Rocky movie after they watched the first or second one and felt disappointed about the series. Another thing could be that people just hate the movie and do not want to rate it. Therefore, ratings are missing. If we omit all the NA observations,the ones left are obervations who have watched every rockly movie. Obviously, this group likes Rocky Movie and thinks highly of the movie.As a result, the mean ratings of movies from this group is much higher than ratings from all of observations. The rating of Rocky 5 is corrlated with ratings of Rocky 2,Rocky 3 and Rocky 4, so the missing vlaue is not at random. Omitting all the NA observations, that is deleting the ratings from other groups such as people who dislike Rocky movie,  will cause bias.

#e

The mean, median and mode are the three measures of central tendency. Using them to replace missing value will reduce the variance and standard deviation of the data. In Rocky movie data, over 90 percent observations have missing data. Using one single value to represent so many missing value obviously will cause bias.

#f
```{r}
RatedRocky5<-rockyDB[!is.na(rockyDB$Rocky5),]
RatedRocky5<-RatedRocky5 %>%
mutate(isMissing1 = ifelse(is.na(Rocky1),1,0))%>%
mutate(isMissing2 = ifelse(is.na(Rocky2),1,0))%>%
mutate(isMissing3 = ifelse(is.na(Rocky3),1,0))%>%
mutate(isMissing4 = ifelse(is.na(Rocky4),1,0))

# test whether having missing ratings in"Rocky1",.."Rocky4" is correlated with ratings for "Rocky5"
cor.test(RatedRocky5$isMissing1,RatedRocky5$Rocky5)
cor.test(RatedRocky5$isMissing2,RatedRocky5$Rocky5)
cor.test(RatedRocky5$isMissing3,RatedRocky5$Rocky5)
cor.test(RatedRocky5$isMissing4,RatedRocky5$Rocky5)

#deal with the missing data#
rockyDB_impute<-RatedRocky5
rockyDB_impute[ , 2:5][is.na(rockyDB_impute[ , 2:5])] = 0 
```

The p-value in cor.test(isMissing1, Rocky5) is 87.8%, much higher than 5%, but the p-value in other three tests are all smaller than 5%. Therefore, having missing ratings in Rocky1 is not statistically significant correlated with ratings for Rocky5 and they are missing at random. Deleting the missing records and imputation can be two useful approaches to deal with the missing value. There are statistically significant correlation between missing ratings in Rocky2, Rocky3 and Rocky4 and ratings for Rocky5. They are not missing at random, so deleting missing ratings in these three movies will cause bias. In order to avoid a reduction in sample size, we decide to replace missing values with 0 in all previous four Rocky movies and use variables "is Missing 1"..."isMissing 4" to capture how the values that are missing are different than the ones that arenâ€™t.


##Part 3
```{r}
fmla1<-Rocky5 ~ Rocky1 + Rocky2 + Rocky3 + Rocky4
```

##a
```{r}
model1<-lm(fmla1,rockyDB_noNA)
summary(model1)
```
We firstly created a model of Rocky5 with respect of Rocky1, Rocky2, Rocky3 and Rocky4 within rockyDB_noNA dataset. We could see that the rating of Rocky1, Rocky2, Rocky3 and Rocky4 all have significant influence on the rating of Rocky5, as the p-values of their coefficient are all less than 0.05. However, the rating of Rocky1 has a negative effect on the rating of Rocky5 while the rest all have a positive effects, according to their predicted coefficients. This model's R squared is 0.4164 and adjusted R squared is 0.4159. 
##b
```{r}
model2<-lm(fmla1,rockyDB_impute)
summary(model2)
cbind(model1$coefficients,model2$coefficients)
```
Then we created a same regression but with a different dataset, rockyDB_impute. We notice that only the rating of Rocky3 and Rocky4 have positive imfluence on the rating of Rocky5 as only ther p-values are less than 0.05. This model's R squared is 0.1979 while adjusted R squared is 0.1975. Altough the former model has a bigger R squared, it is biased due to the missing data we have talked above. Meanwhile we could compare the coefficients of these variables in these two models. We could see that the absolute value of variable coefficients in the first model are all bigger than in the second model but they are all in the same symbol. This is to say, these variables all have same effects on our dependent variable but the extent of these influences are different. Additionally, the significances of these variable are quite different under these two models. All the variables are significant in the first model while only Rocky3 and Rocky4 are significant in the second model.
##c

```{r}
fmla2<-Rocky5 ~ Rocky1 + Rocky2 + Rocky3 + Rocky4 + isMissing2 + isMissing3 + isMissing4
model3<-lm(fmla2,rockyDB_impute)
cbind(model2=summary(model2)$r.squared,model3=summary(model3)$r.squared)
cbind(model2=summary(model2)$adj.r.squared,model3=summary(model3)$adj.r.squared)
```
Then we added variables to capture the difference between missing data and nonmissing data. Then we found adding these variables increased both R squared and adjusted R squared from 0.198 to 0.37. 

```{r}
rocky1Vec = c('+Rocky1','+poly(Rocky1,2)')
rocky2Vec = c('+Rocky2','+poly(Rocky2,2)','+isMissing2')
rocky3Vec = c('+Rocky3','+poly(Rocky3,2)','+isMissing3')
rocky4Vec = c('+Rocky4','+poly(Rocky4,2)','+isMissing4')

formulaSet = paste('Rocky5~1',
apply(expand.grid(rocky1Vec,rocky2Vec,rocky3Vec,rocky4Vec),1,paste,collapse=''))
formulaSet

modellist<-list()
for (i in 1:54) {
modellist[[i]]<-(lm(as.formula(formulaSet[i]),data=rockyDB_impute))
}


set.seed(1)  
train.index <- sample(c(1:dim(rockyDB_impute)[1]), dim(rockyDB_impute)[1]*0.8)  
train.df <- rockyDB_impute[train.index, ]
valid.df <- rockyDB_impute[-train.index, ]

modellist2<-list()
mselist<-list()

for (i in 1:54) {
modellist2[[i]]<-(lm(as.formula(formulaSet[i]),data=train.df))
mselist[[i]]<-mean((valid.df$Rocky5- predict(modellist2[[i]],newdata = valid.df))^2)
}
mselist
modellist2[[30]]
summary(modellist2[[30]])
```
Then we created 4 vectors to automatically generate different models. These vectors contains following variables: Rocky1, poly(Rocky1, 2), Rocky2, poly(Rocky2,2), isMissing2, Rocky3, poly(Rocky3,2), isMissing3, Rocky4, poly(Rocky4,2), isMissing4. We created 54 models from these variables. The reason why we include polynominal variables in our model is because we want to test whether there is no-linear correlation between rating of Rocky5 with ratings of other movies. Besides, we also include isMissing variables indicating the missing value. As we talked above, these missing value is not missing at random and is not independent from our dependent variable. Therefore, we included a series of isMissing variables. However, we did not include isMissing1 as we notice we cannot reject the independence between isMissing1 and Rocky5. Thus we created 54 models with rockyDB_impute and store the models as modellist1. Then we seperated our original dataset into training set and validation set, and used the same formularset to generate models within the training set. We utilized training data to generate models and made predictions for validation set. We firstly generated 54 models with training data and store it as modellist2. Then we made predictions based on models in modellist2 and calculated out of sample MSE of these models. We found the 30th model in the modellist2 has the least MSE, 1.051784. 

The regression of the best model (with least MSE) is Rocky5 = 2.9826 + 1.3575Rocky1 + 8.6979Rocky1^2 + 0.1648isMissing2 + 22.3820Rocky3 + 20.2137Rocky3^2 + 25.8683Rocky4 + 19.3670Rocky4^2. All the variables' coefficients are significant except isMissing2 and R squared is around 0.35. We could conclude that all these significant variables have positive effects on rating of Rocky5 as their coefficients are bigger than 0. And we could also notice Rocky3, Rocky3^2, Rocky4 and Rocky4^2 have greater impact on our dependent variable than the rest variables as their coefficients are around 20, which is a comparatively big number. 
